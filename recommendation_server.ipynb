{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dbd078-820c-46db-99ad-0c10c85a6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서버용 import\n",
    "# pip install Flask\n",
    "from flask import Flask, request, jsonify, session\n",
    "\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2bbe40a-b7b3-4080-a073-189d3647a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_codes = {\n",
    "    '음식료': [10, 11, 12],\n",
    "    '섬유의복': [13, 14, 15],\n",
    "    '목재종이': [16, 17, 18],\n",
    "    '석유화학': [19, 20, 21, 22],\n",
    "    '비금속': [23],\n",
    "    '철강': [24],\n",
    "    '기계': [25, 29],\n",
    "    '전기전자': [26, 27, 28],\n",
    "    '운송장비': [30, 31],\n",
    "    '기타': [32, 33, 34]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f10369b-cfc3-46ae-973f-90c47f31b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from googletrans import Translator\n",
    "import string\n",
    "import folium\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14768537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 산업단지 기본 데이터 불러오기\n",
    "df_park = pd.read_excel('Data/COMPLEX_BASIC.xlsx')\n",
    "df_concentration_all = pd.read_excel('Data/업종집적도_결과.xlsx')\n",
    "df_similarity = pd.read_excel('모든공장유사도용0621.xlsx', nrows=97615)\n",
    "df_trans = pd.read_excel('Data/COMPLEX_TRANS.xlsx')\n",
    "df_worker = pd.read_excel('Data/노동력.xlsx')\n",
    "\n",
    "# GloVe 모델 로드\n",
    "# 원자재, 생산품 유사도용\n",
    "glove_txt_file_path = 'glove.6B.300d.txt'\n",
    "\n",
    "# 전체 불러오기 (메모리 문제)(속도를 버리고 정확도를 얻음) => ***VS CODE에서 돌리기***\n",
    "def load_all_glove_vectors(glove_txt_file_path):\n",
    "    glove_dict = {}\n",
    "    with open(glove_txt_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            glove_dict[word] = vector\n",
    "\n",
    "    return glove_dict\n",
    "\n",
    "# GloVe 벡터 로드 시도\n",
    "try:\n",
    "    glove_dict = load_all_glove_vectors(glove_txt_file_path)\n",
    "    print(\"GloVe 벡터 로드 완료\")\n",
    "except Exception as e:\n",
    "    print(f\"GloVe 벡터 로드 중 오류 발생: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# glove 벡터 가져오기(문장 단위)\n",
    "def get_glove_vector(sentence, glove_dict):\n",
    "    # 문장을 단어단위로 쪼개기\n",
    "    words = sentence.split()\n",
    "\n",
    "    # 벡터 담을 리스트\n",
    "    vectors = []\n",
    "\n",
    "    # 단어 훑고 glove 가져오기\n",
    "    for word in words:\n",
    "        vector = glove_dict.get(word)\n",
    "        if vector is not None:\n",
    "            vectors.append(vector)\n",
    "\n",
    "    # 벡터 평균 계산\n",
    "    if len(vectors) > 0:\n",
    "        # Compute the average of the vectors\n",
    "        avg_vector = np.mean(vectors, axis=0)\n",
    "        return avg_vector\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 유사도 계산\n",
    "def calculate_similarity(user_input_sentence, file_data_sentence, glove_dict):\n",
    "    # 두 벡터 가져오기\n",
    "    vector1 = get_glove_vector(user_input_sentence, glove_dict)    # 유저 입력값 벡터\n",
    "    vector2 = get_glove_vector(file_data_sentence, glove_dict)    # 파일의 데이터 벡터\n",
    "\n",
    "    # 벡터중 하나라도 존재하지 않는 경우 유사도 0\n",
    "    if vector1 is None or vector2 is None:\n",
    "        return None\n",
    "\n",
    "    # 유사도 계산\n",
    "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    return cosine_similarity\n",
    "\n",
    "\n",
    "# 사용자의 입력값 한글 -> 영어 번역\n",
    "def translate_to_english(text, dest='en', src='auto'):\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        translation = translator.translate(text, dest=dest, src=src)\n",
    "        return translation.text\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating text '{text}': {e}\")\n",
    "        return None  # 오류 발생 시 None 반환\n",
    "\n",
    "    # 예외 처리 추가 예시\n",
    "def translate_with_fallback(text):\n",
    "    translated_text = translate_to_english(text)\n",
    "    if translated_text is None:\n",
    "        print(f\"Translation failed for text: '{text}' <-\")\n",
    "        return ''  # 또는 처리할 수 있는 기본 값\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2e5b3-a280-40be-b5ae-56ba83dd06c1",
   "metadata": {},
   "source": [
    "# 한꺼번에 처리하는 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ec176e-8030-4c9d-b51a-2f7e239a0ec7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   단지명  시도유사도\n",
      "0             GW일반산업단지      0\n",
      "1    I-Food Park일반산업단지      1\n",
      "2          KCC울산일반산업단지      0\n",
      "3           가평목동일반산업단지      1\n",
      "4           강릉과학일반산업단지      0\n",
      "..                 ...    ...\n",
      "482         화성주곡일반산업단지      1\n",
      "483       화성향남제약일반산업단지      1\n",
      "484         화성화남일반산업단지      1\n",
      "485           화순지방산업단지      0\n",
      "486         횡성우천일반산업단지      0\n",
      "\n",
      "[487 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "@app.route('/recommendation', methods=['POST'])\n",
    "def recommendation():\n",
    "    data = request.json\n",
    "    region = data.get('region')\n",
    "    transportation = data.get('transportation')\n",
    "    landPrice = data.get('landPrice')\n",
    "    industry = data.get('industry')\n",
    "    product = data.get('product')\n",
    "    rawMaterial = data.get('rawMaterial')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # 시도 유사도 계산\n",
    "    user_region_input = region\n",
    "    user_regions = [region.strip() for region in user_region_input.split(',')]\n",
    "    df_park['시도유사도'] = df_park['시도'].apply(lambda x: 1 if x in user_regions else 0)\n",
    "    df_sido_similarity = df_park.groupby('단지명', as_index=False).agg({'시도유사도': 'max'})\n",
    "\n",
    "\n",
    "    # 업종집적도 계산\n",
    "    user_industry = industry\n",
    "    industry_col_int = f\"{user_industry}_업종집적도\"\n",
    "    df_concentration = df_concentration_all[['단지명', industry_col_int]]\n",
    "    df_concentration = df_concentration.rename(columns={industry_col_int: \"업종집적도\"}).sort_values(by='업종집적도', ascending=False)\n",
    "\n",
    "\n",
    "    # 토지 지가 점수 계산\n",
    "    preferred_price_max = landPrice\n",
    "    beta = 5\n",
    "\n",
    "    def calculate_penalty_score(price, max_price, beta):\n",
    "        if price <= max_price:\n",
    "            return 1\n",
    "        excess_ratio = (price - max_price) / max_price\n",
    "        return 1 / np.exp(beta * excess_ratio)\n",
    "    df_park['토지 개별공시지가 점수'] = df_park['산업용지 평균분양가 (원/㎡)'].apply(\n",
    "        lambda x: calculate_penalty_score(x, preferred_price_max, beta)\n",
    "    )\n",
    "    df_land_price_score = df_park[['단지명', '토지 개별공시지가 점수']].drop_duplicates()\n",
    "\n",
    "\n",
    "    # 원자재 유사도 점수 계산\n",
    "    user_need_item = rawMaterial\n",
    "    user_input_english = translate_to_english(user_need_item).lower()\n",
    "    translated_text_need = translate_with_fallback(user_need_item)\n",
    "    if translated_text_need:\n",
    "        user_input_english = translated_text_need.lower()\n",
    "    else:\n",
    "        print(\"오류. 생산품이나 원자재 존재X\")\n",
    "\n",
    "    # \"원자재_영어\" 유사도 계산\n",
    "    raw_materials_df = df_similarity[['단지명', '원자재_영어']].dropna(subset=['원자재_영어'])\n",
    "    raw_materials_df['원자재_영어'] = raw_materials_df['원자재_영어'].str.lower()  # 소문자로 변환\n",
    "    raw_materials_df['원자재_유사도'] = raw_materials_df['원자재_영어'].apply(\n",
    "        lambda x: calculate_similarity(user_input_english, x, glove_dict)\n",
    "    )\n",
    "\n",
    "    # 유사도 0.5 이상인 경우만 가져오기 \n",
    "    filtered_df_raw_materials = raw_materials_df[raw_materials_df['원자재_유사도'] >= 0.5]\n",
    "\n",
    "    # 유사 공장 수 및 유사도 평균값 구하기 \n",
    "    sim_fac_cnt_raw_materials = filtered_df_raw_materials.groupby('단지명').size().reset_index(name='유사 원자재 사용공장 수')\n",
    "    mean_similarity_raw_materials = filtered_df_raw_materials.groupby('단지명')['원자재_유사도'].mean().reset_index(name='원자재 유사도 평균값')\n",
    "    sim_fac_cnt_raw_materials = sim_fac_cnt_raw_materials.merge(mean_similarity_raw_materials, on='단지명')\n",
    "\n",
    "    # 유사도와 공장 수의 가중치 비율\n",
    "    weight_mean_raw_materials = 0.5\n",
    "    weight_count_raw_materials = 0.5\n",
    "    sim_fac_cnt_raw_materials['최종 유사도'] = (\n",
    "        sim_fac_cnt_raw_materials['원자재 유사도 평균값'] * weight_mean_raw_materials +\n",
    "        sim_fac_cnt_raw_materials['유사 원자재 사용공장 수'] * weight_count_raw_materials\n",
    "    )\n",
    "\n",
    "    # 0.5~1로 정규화\n",
    "    min_final_sim_raw_materials = sim_fac_cnt_raw_materials['최종 유사도'].min()\n",
    "    max_final_sim_raw_materials = sim_fac_cnt_raw_materials['최종 유사도'].max()\n",
    "    sim_fac_cnt_raw_materials['원자재 유사도'] = 0.5 + (\n",
    "        (sim_fac_cnt_raw_materials['최종 유사도'] - min_final_sim_raw_materials) /\n",
    "        (max_final_sim_raw_materials - min_final_sim_raw_materials)\n",
    "    ) * 0.5\n",
    "\n",
    "    # 원자재 유사도 최종 결과\n",
    "    raw_materials_result = sim_fac_cnt_raw_materials[['단지명', '원자재 유사도']].sort_values(by='원자재 유사도', ascending=False).drop_duplicates(subset='단지명')\n",
    "\n",
    "\n",
    "    # 생산품 유사도 \n",
    "    # 사용자의 생산품 입력\n",
    "    user_input_item = product\n",
    "\n",
    "    # 번역\n",
    "    user_input_made_english = translate_to_english(user_input_item).lower()\n",
    "\n",
    "    # 번역\n",
    "    translated_text = translate_with_fallback(user_input_item)\n",
    "    if translated_text:\n",
    "        user_input_made_english = translated_text.lower()\n",
    "\n",
    "    # \"생산품_영어\" 유사도 계산\n",
    "    products_df = df_similarity[['단지명', '생산품_영어']].dropna(subset=['생산품_영어'])    # 결측치 제거\n",
    "    products_df['생산품_영어'] = products_df['생산품_영어'].str.lower()  # 소문자로 변환\n",
    "    products_df['생산품_유사도'] = products_df['생산품_영어'].apply(\n",
    "        lambda x: calculate_similarity(user_input_made_english, x, glove_dict)\n",
    "    )    # 코싸인 유사도 계산\n",
    "\n",
    "    # 유사도 0.5 이상인 경우만 가져오기 \n",
    "    filtered_df_products = products_df[products_df['생산품_유사도'] >= 0.5]\n",
    "\n",
    "    # 유사 공장 수 및 유사도 평균값 구하기 \n",
    "    sim_fac_cnt_products = filtered_df_products.groupby('단지명').size().reset_index(name='유사 생산품 제작공장 수')\n",
    "    mean_similarity_products = filtered_df_products.groupby('단지명')['생산품_유사도'].mean().reset_index(name='생산품 유사도 평균값')\n",
    "    sim_fac_cnt_products = sim_fac_cnt_products.merge(mean_similarity_products, on='단지명')\n",
    "\n",
    "    # 유사도와 공장 수의 가중치 비율\n",
    "    weight_mean_products = 0.5\n",
    "    weight_count_products = 0.5\n",
    "    sim_fac_cnt_products['최종 유사도'] = (\n",
    "        sim_fac_cnt_products['생산품 유사도 평균값'] * weight_mean_products +\n",
    "        sim_fac_cnt_products['유사 생산품 제작공장 수'] * weight_count_products\n",
    "    )\n",
    "\n",
    "    # 0.5~1로 정규화\n",
    "    min_final_sim_products = sim_fac_cnt_products['최종 유사도'].min()\n",
    "    max_final_sim_products = sim_fac_cnt_products['최종 유사도'].max()\n",
    "    sim_fac_cnt_products['생산품 유사도'] = 0.5 + (\n",
    "        (sim_fac_cnt_products['최종 유사도'] - min_final_sim_products) /\n",
    "        (max_final_sim_products - min_final_sim_products)\n",
    "    ) * 0.5\n",
    "\n",
    "    # 생산품 유사도 결과\n",
    "    products_result = sim_fac_cnt_products[['단지명', '생산품 유사도']].sort_values(by='생산품 유사도', ascending=False).drop_duplicates(subset='단지명')\n",
    "\n",
    "\n",
    "    # 교통 접근성에 대한 사용자 선호도 입력\n",
    "\n",
    "    user_priorities = {\n",
    "        '고속도로 인접도': transportation.get('highwayPreference'),\n",
    "        '철도역 인접도': transportation.get('railwayPreference'),\n",
    "        '항만 인접도': transportation.get('portPreference'),\n",
    "        '공항 인접도': transportation.get('airportPreference')\n",
    "    }\n",
    "\n",
    "    # 사용자 교통 인접 선호도 입력값에 따라 점수 생성 ex) 인접 선호도 순위(1,2,3,4) -> 인접도 점수(4,3,2,1)\n",
    "    priority_scores = {key: 5 - value for key, value in user_priorities.items()}\n",
    "    print(\"사용자 선호도 가중치:\", priority_scores)\n",
    "\n",
    "    # 페널티를 적용한 가중치 점수 계산\n",
    "    df_trans['고속도로 가중치'] = df_trans['고속도로 인접도 점수'].apply(\n",
    "        lambda x: x * priority_scores['고속도로 인접도'] + (x - priority_scores['고속도로 인접도']) if x < priority_scores['고속도로 인접도'] else x * priority_scores['고속도로 인접도'])\n",
    "\n",
    "    df_trans['철도 가중치'] = df_trans['철도 인접도 점수'].apply(\n",
    "        lambda x: x * priority_scores['철도역 인접도'] + (x - priority_scores['철도역 인접도']) if x < priority_scores['철도역 인접도'] else x * priority_scores['철도역 인접도'])\n",
    "\n",
    "    df_trans['항만 가중치'] = df_trans['항만 인접도 점수'].apply(\n",
    "        lambda x: x * priority_scores['항만 인접도'] + (x - priority_scores['항만 인접도']) if x < priority_scores['항만 인접도'] else x * priority_scores['항만 인접도'])\n",
    "\n",
    "    df_trans['공항 가중치'] = df_trans['공항 인접도 점수'].apply(\n",
    "        lambda x: x * priority_scores['공항 인접도'] + (x - priority_scores['공항 인접도']) if x < priority_scores['공항 인접도'] else x * priority_scores['공항 인접도'])\n",
    "\n",
    "    # 총 가중치 점수 계산\n",
    "    df_trans['총 가중치 점수'] = (\n",
    "        df_trans['고속도로 가중치'] +\n",
    "        df_trans['철도 가중치'] +\n",
    "        df_trans['항만 가중치'] +\n",
    "        df_trans['공항 가중치']\n",
    "    )\n",
    "\n",
    "    # 정규화된 총 가중치 점수 계산\n",
    "    df_trans['교통 점수'] = (df_trans['총 가중치 점수'] - df_trans['총 가중치 점수'].min()) / (df_trans['총 가중치 점수'].max() - df_trans['총 가중치 점수'].min())\n",
    "\n",
    "    # 단지명과 교통 점수로 이루어진 최종 데이터프레임 생성\n",
    "    df_trans_result = df_trans[['단지명', '교통 점수']].sort_values(by='교통 점수', ascending=False).drop_duplicates(subset='단지명')\n",
    "\n",
    "    \n",
    "    # 노동력 점수\n",
    "    worker_result = df_worker[['단지명', '노동력']].sort_values(by='노동력', ascending=False).drop_duplicates(subset='단지명')\n",
    "\n",
    "    \n",
    "    # 가중치 점수\n",
    "    weight_region = 0.142857  # 시도 유사도 # df_sido_similarity [['단지명', '시도유사도']]\n",
    "    weight_industry = 0.142857  # 업종집적도 # df_concentration [['단지명', '업종집적도']]\n",
    "    weight_price_penalty = 0.142857  # 토지 개별공시지가 점수 # df_land_price_score [['단지명', '토지 개별공시지가 점수']]\n",
    "    weight_raw_material = 0.142857  # 원자재 유사도 # raw_materials_result [['단지명', '원자재 유사도']]\n",
    "    weight_product = 0.142857  # 생산품 유사도 # products_result [['단지명', '생산품 유사도']]\n",
    "    weight_transport = 0.142857  # 교통 접근성 점수 # df_trans_result [['단지명', '교통 점수']]\n",
    "    weight_pop = 0.142857  # 노동력 # worker_result [['단지명', '노동력']]\n",
    "\n",
    "\n",
    "    \n",
    "    # 최종 결과\n",
    "    # 단지명 기준으로 데이터 병합\n",
    "    merged_df = df_sido_similarity.merge(df_concentration, on='단지명', how='left')\\\n",
    "        .merge(df_land_price_score, on='단지명', how='left')\\\n",
    "        .merge(raw_materials_result, on='단지명', how='left')\\\n",
    "        .merge(products_result, on='단지명', how='left')\\\n",
    "        .merge(df_trans_result, on='단지명', how='left')\\\n",
    "        .merge(worker_result, on='단지명', how='left')\n",
    "\n",
    "    # 최종 유사도 계산\n",
    "    merged_df['최종 유사도'] = (\n",
    "        merged_df['시도유사도'] * weight_region +\n",
    "        merged_df['업종집적도'] * weight_industry +\n",
    "        merged_df['토지 개별공시지가 점수'] * weight_price_penalty +\n",
    "        merged_df['원자재 유사도'] * weight_raw_material +\n",
    "        merged_df['생산품 유사도'] * weight_product +\n",
    "        merged_df['교통 점수'] * weight_transport +\n",
    "        merged_df['노동력'] * weight_pop\n",
    "    )\n",
    "\n",
    "    # NaN 값을 0으로 채우기\n",
    "    merged_df.fillna(0, inplace=True)\n",
    "\n",
    "    # 4. 필요한 컬럼만 추출 (\"단지명\"과 \"최종 유사도\")\n",
    "    final_result = merged_df[['단지명', '최종 유사도']]\n",
    "\n",
    "\n",
    "    # '최종 유사도' 컬럼을 기준으로 내림차순 정렬\n",
    "    sorted_df = merged_df.sort_values(by='최종 유사도', ascending=False)\n",
    "\n",
    "    # 인덱스를 새로운 컬럼으로 추가하여 순위를 매김 (기존 인덱스를 리셋하고 1부터 시작하는 순서로 설정)\n",
    "    sorted_df = sorted_df.reset_index(drop=True)\n",
    "\n",
    "    # 순위 컬럼 추가 (1부터 시작하는 순위)\n",
    "    sorted_df['순위'] = sorted_df.index + 1\n",
    "\n",
    "    # DataFrame 컬럼명을 변경하는 매핑 딕셔너리 생성 ＃ 스프링 ＪＳＯＮ 연계용\n",
    "    column_mapping = {\n",
    "        '순위': 'rankResult',\n",
    "        '단지명': 'complexName',\n",
    "        '최종 유사도': 'finalSimilarityScore',\n",
    "        '시도유사도': 'regionScore',\n",
    "        '업종집적도': 'industryScore',\n",
    "        '토지 개별공시지가 점수': 'landPriceScore',\n",
    "        '원자재 유사도': 'rawMaterialScore',\n",
    "        '생산품 유사도': 'productScore',\n",
    "        '교통 점수': 'transportScore',\n",
    "        '노동력': 'workerScore'\n",
    "    }\n",
    "\n",
    "    # 정렬된 결과 출력 (순위 포함)\n",
    "    result = sorted_df[['순위', '단지명', '최종 유사도', '시도유사도', '업종집적도', '토지 개별공시지가 점수', '원자재 유사도', '생산품 유사도', '교통 점수', '노동력']].head(10)\n",
    "\n",
    "    # 컬럼명을 영어로 변경\n",
    "    result = result.rename(columns=column_mapping)\n",
    "\n",
    "    # 최종 결과 JSON 변환\n",
    "    result_json = result.to_json(orient='records', force_ascii=False)\n",
    "    \n",
    "    # 파이썬 서버에서 JSON 데이터 확인\n",
    "    print(\"서버에서 반환할 JSON 데이터: \", result_json)  # JSON 데이터를 콘솔에서 확인 ＃ 디버깅용\n",
    "    \n",
    "    # JSON 데이터를 그대로 반환 (jsonify는 불필요)\n",
    "    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4506f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)    # 파이썬 서버 포트 번호 5000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
